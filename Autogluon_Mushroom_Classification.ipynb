{"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":76727,"databundleVersionId":9045607,"sourceType":"competition"},{"sourceId":9269264,"sourceType":"datasetVersion","datasetId":5609366}],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"colab":{"provenance":[],"machine_shape":"hm"}},"nbformat_minor":0,"nbformat":4,"cells":[{"cell_type":"markdown","source":["# **Mushroom Classification - Playground Series**\n"],"metadata":{"id":"Ze95mwyGdCT_"}},{"cell_type":"markdown","source":["# **Set-up**"],"metadata":{"id":"ezSLP30AdCUB"}},{"cell_type":"code","source":["# AutoGluon is a SOTA AutoML framework\n","%pip install -q setuptools wheel autogluon.tabular[all,skex] dask[dataframe]\n","%pip install -U -q ipywidgets cloudpickle==2.2.1"],"metadata":{"execution":{"iopub.status.busy":"2024-08-29T12:44:25.349478Z","iopub.execute_input":"2024-08-29T12:44:25.349889Z","iopub.status.idle":"2024-08-29T12:47:54.176635Z","shell.execute_reply.started":"2024-08-29T12:44:25.349851Z","shell.execute_reply":"2024-08-29T12:47:54.175531Z"},"trusted":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"70Uj1yQ5dCUC","outputId":"048fc9e8-04a1-4480-add5-2d567e20f0b9","executionInfo":{"status":"ok","timestamp":1724941058929,"user_tz":240,"elapsed":139026,"user":{"displayName":"Fabián Alberto Reyes Madrid","userId":"11772448517145602220"}}},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.4/60.4 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m234.8/234.8 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.4/63.4 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.6/64.6 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.2/98.2 MB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.9/241.9 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m74.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.2/142.2 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.5/10.5 MB\u001b[0m \u001b[31m49.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.4/38.4 MB\u001b[0m \u001b[31m45.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m779.1/779.1 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m80.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m67.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.1/168.1 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.1/297.1 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m312.1/312.1 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.1/139.1 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.1/65.1 MB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m55.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.5/12.5 MB\u001b[0m \u001b[31m80.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m69.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.7/82.7 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m80.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.4/201.4 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m67.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.9/468.9 kB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","osqp 0.6.7.post0 requires scipy!=1.12.0,>=0.13.2, but you have scipy 1.12.0 which is incompatible.\n","torchaudio 2.4.0+cu121 requires torch==2.4.0, but you have torch 2.3.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.8/139.8 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import pandas as pd\n","import numpy as np\n","import warnings\n","import os\n","import cloudpickle\n","from autogluon.tabular import TabularDataset, TabularPredictor\n","warnings.filterwarnings('ignore')"],"metadata":{"execution":{"iopub.status.busy":"2024-08-29T12:47:54.178834Z","iopub.execute_input":"2024-08-29T12:47:54.179175Z","iopub.status.idle":"2024-08-29T12:47:55.950882Z","shell.execute_reply.started":"2024-08-29T12:47:54.179140Z","shell.execute_reply":"2024-08-29T12:47:55.950090Z"},"trusted":true,"id":"31o5LzYKdCUD","executionInfo":{"status":"ok","timestamp":1724941342143,"user_tz":240,"elapsed":294,"user":{"displayName":"Fabián Alberto Reyes Madrid","userId":"11772448517145602220"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qkVDbsnbgX73","executionInfo":{"status":"ok","timestamp":1724941192844,"user_tz":240,"elapsed":18837,"user":{"displayName":"Fabián Alberto Reyes Madrid","userId":"11772448517145602220"}},"outputId":"44d1d5c6-04ab-49a9-a041-e3f05d4d869e"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["base_path = os.getenv('DATA_FOLDER_PATH', '/content/drive/MyDrive/DS_Projects/Playground_Series/ps4s8_Mushroom_Classification/Data/')\n","\n","train_data = TabularDataset(os.path.join(base_path, 'train_ready_1s.csv'))\n","test_data = TabularDataset(os.path.join(base_path, 'test_ready_1s.csv'))"],"metadata":{"execution":{"iopub.status.busy":"2024-08-29T12:47:55.952206Z","iopub.execute_input":"2024-08-29T12:47:55.952680Z","iopub.status.idle":"2024-08-29T12:48:16.647920Z","shell.execute_reply.started":"2024-08-29T12:47:55.952646Z","shell.execute_reply":"2024-08-29T12:48:16.647048Z"},"trusted":true,"id":"6gBNG_0CdCUD","executionInfo":{"status":"ok","timestamp":1724941393359,"user_tz":240,"elapsed":19960,"user":{"displayName":"Fabián Alberto Reyes Madrid","userId":"11772448517145602220"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# Setting up\n","eval_metric = 'log_loss'\n","label = 'class'\n","\n","# Models to exclude\n","excluded_model_types = ['KNN']\n","\n","# Initialize the TabularPredictor\n","predictor = TabularPredictor(label=label, eval_metric=eval_metric)\n","\n","# Fit the model\n","predictor.fit(train_data=train_data,\n","              time_limit=3600*12,\n","              presets=\"best_quality\",\n","              excluded_model_types=excluded_model_types\n",")"],"metadata":{"execution":{"iopub.status.busy":"2024-08-29T12:48:16.649661Z","iopub.execute_input":"2024-08-29T12:48:16.649956Z"},"trusted":true,"id":"XWjqEtwbdCUE","outputId":"acc9490d-26fa-4c31-91d0-e81ceb2a8239","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1724968540533,"user_tz":240,"elapsed":27138613,"user":{"displayName":"Fabián Alberto Reyes Madrid","userId":"11772448517145602220"}}},"execution_count":10,"outputs":[{"output_type":"stream","name":"stderr","text":["No path specified. Models will be saved in: \"AutogluonModels/ag-20240829_142322\"\n","Verbosity: 2 (Standard Logging)\n","=================== System Info ===================\n","AutoGluon Version:  1.1.1\n","Python Version:     3.10.12\n","Operating System:   Linux\n","Platform Machine:   x86_64\n","Platform Version:   #1 SMP PREEMPT_DYNAMIC Thu Jun 27 21:05:47 UTC 2024\n","CPU Count:          8\n","Memory Avail:       48.23 GB / 50.99 GB (94.6%)\n","Disk Space Avail:   183.26 GB / 225.83 GB (81.1%)\n","===================================================\n","Presets specified: ['best_quality']\n","Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n","Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n","DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n","\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n","\tRunning DyStack for up to 10800s of the 43200s of remaining time (25%).\n","\tRunning DyStack sub-fit in a ray process to avoid memory leakage. Enabling ray logging (enable_ray_logging=True). Specify `ds_args={'enable_ray_logging': False}` if you experience logging issues.\n","2024-08-29 14:23:25,563\tINFO worker.py:1743 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n","\t\tContext path: \"AutogluonModels/ag-20240829_142322/ds_sub_fit/sub_fit_ho\"\n","\u001b[36m(_dystack pid=7231)\u001b[0m Running DyStack sub-fit ...\n","\u001b[36m(_dystack pid=7231)\u001b[0m Beginning AutoGluon training ... Time limit = 10795s\n","\u001b[36m(_dystack pid=7231)\u001b[0m AutoGluon will save models to \"AutogluonModels/ag-20240829_142322/ds_sub_fit/sub_fit_ho\"\n","\u001b[36m(_dystack pid=7231)\u001b[0m Train Data Rows:    2770617\n","\u001b[36m(_dystack pid=7231)\u001b[0m Train Data Columns: 21\n","\u001b[36m(_dystack pid=7231)\u001b[0m Label Column:       class\n","\u001b[36m(_dystack pid=7231)\u001b[0m Problem Type:       binary\n","\u001b[36m(_dystack pid=7231)\u001b[0m Preprocessing data ...\n","\u001b[36m(_dystack pid=7231)\u001b[0m Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n","\u001b[36m(_dystack pid=7231)\u001b[0m Using Feature Generators to preprocess the data ...\n","\u001b[36m(_dystack pid=7231)\u001b[0m Fitting AutoMLPipelineFeatureGenerator...\n","\u001b[36m(_dystack pid=7231)\u001b[0m \tAvailable Memory:                    49715.29 MB\n","\u001b[36m(_dystack pid=7231)\u001b[0m \tTrain Data (Original)  Memory Usage: 2506.31 MB (5.0% of available memory)\n","\u001b[36m(_dystack pid=7231)\u001b[0m \tWarning: Data size prior to feature transformation consumes 5.0% of available memory. Consider increasing memory or subsampling the data to avoid instability.\n","\u001b[36m(_dystack pid=7231)\u001b[0m \tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n","\u001b[36m(_dystack pid=7231)\u001b[0m \tStage 1 Generators:\n","\u001b[36m(_dystack pid=7231)\u001b[0m \t\tFitting AsTypeFeatureGenerator...\n","\u001b[36m(_dystack pid=7231)\u001b[0m \t\t\tNote: Converting 2 features to boolean dtype as they only contain 2 unique values.\n","\u001b[36m(_dystack pid=7231)\u001b[0m \tStage 2 Generators:\n","\u001b[36m(_dystack pid=7231)\u001b[0m \t\tFitting FillNaFeatureGenerator...\n","\u001b[36m(_dystack pid=7231)\u001b[0m \tStage 3 Generators:\n","\u001b[36m(_dystack pid=7231)\u001b[0m \t\tFitting IdentityFeatureGenerator...\n","\u001b[36m(_dystack pid=7231)\u001b[0m \t\tFitting CategoryFeatureGenerator...\n","\u001b[36m(_dystack pid=7231)\u001b[0m \t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n","\u001b[36m(_dystack pid=7231)\u001b[0m \tStage 4 Generators:\n","\u001b[36m(_dystack pid=7231)\u001b[0m \t\tFitting DropUniqueFeatureGenerator...\n","\u001b[36m(_dystack pid=7231)\u001b[0m \tStage 5 Generators:\n","\u001b[36m(_dystack pid=7231)\u001b[0m \t\tFitting DropDuplicatesFeatureGenerator...\n","\u001b[36m(_dystack pid=7231)\u001b[0m \tTypes of features in original data (raw dtype, special dtypes):\n","\u001b[36m(_dystack pid=7231)\u001b[0m \t\t('float', [])  :  3 | ['cap_diameter', 'stem_height', 'stem_width']\n","\u001b[36m(_dystack pid=7231)\u001b[0m \t\t('int', [])    :  3 | ['id', 'does_bruise_or_bleed', 'has_ring']\n","\u001b[36m(_dystack pid=7231)\u001b[0m \t\t('object', []) : 15 | ['cap_shape', 'cap_surface', 'cap_color', 'gill_attachment', 'gill_spacing', ...]\n","\u001b[36m(_dystack pid=7231)\u001b[0m \tTypes of features in processed data (raw dtype, special dtypes):\n","\u001b[36m(_dystack pid=7231)\u001b[0m \t\t('category', [])  : 15 | ['cap_shape', 'cap_surface', 'cap_color', 'gill_attachment', 'gill_spacing', ...]\n","\u001b[36m(_dystack pid=7231)\u001b[0m \t\t('float', [])     :  3 | ['cap_diameter', 'stem_height', 'stem_width']\n","\u001b[36m(_dystack pid=7231)\u001b[0m \t\t('int', [])       :  1 | ['id']\n","\u001b[36m(_dystack pid=7231)\u001b[0m \t\t('int', ['bool']) :  2 | ['does_bruise_or_bleed', 'has_ring']\n","\u001b[36m(_dystack pid=7231)\u001b[0m \t24.7s = Fit runtime\n","\u001b[36m(_dystack pid=7231)\u001b[0m \t21 features in original data used to generate 21 features in processed data.\n","\u001b[36m(_dystack pid=7231)\u001b[0m \tTrain Data (Processed) Memory Usage: 129.48 MB (0.3% of available memory)\n","\u001b[36m(_dystack pid=7231)\u001b[0m Data preprocessing and feature engineering runtime = 25.97s ...\n","\u001b[36m(_dystack pid=7231)\u001b[0m AutoGluon will gauge predictive performance using evaluation metric: 'log_loss'\n","\u001b[36m(_dystack pid=7231)\u001b[0m \tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n","\u001b[36m(_dystack pid=7231)\u001b[0m \tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n","\u001b[36m(_dystack pid=7231)\u001b[0m \tTo change this, specify the eval_metric parameter of Predictor()\n","\u001b[36m(_dystack pid=7231)\u001b[0m Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n","\u001b[36m(_dystack pid=7231)\u001b[0m User-specified model hyperparameters to be fit:\n","\u001b[36m(_dystack pid=7231)\u001b[0m {\n","\u001b[36m(_dystack pid=7231)\u001b[0m \t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n","\u001b[36m(_dystack pid=7231)\u001b[0m \t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n","\u001b[36m(_dystack pid=7231)\u001b[0m \t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n","\u001b[36m(_dystack pid=7231)\u001b[0m \t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n","\u001b[36m(_dystack pid=7231)\u001b[0m \t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n","\u001b[36m(_dystack pid=7231)\u001b[0m \t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n","\u001b[36m(_dystack pid=7231)\u001b[0m \t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n","\u001b[36m(_dystack pid=7231)\u001b[0m \t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n","\u001b[36m(_dystack pid=7231)\u001b[0m }\n","\u001b[36m(_dystack pid=7231)\u001b[0m AutoGluon will fit 2 stack levels (L1 to L2) ...\n","\u001b[36m(_dystack pid=7231)\u001b[0m Excluded models: ['KNN'] (Specified by `excluded_model_types`)\n","\u001b[36m(_dystack pid=7231)\u001b[0m Fitting 108 L1 models ...\n","\u001b[36m(_dystack pid=7231)\u001b[0m Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 7177.83s of the 10769.43s of remaining time.\n","\u001b[36m(_dystack pid=7231)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=2.14%)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[36m(_ray_fit pid=8017)\u001b[0m [1000]\tvalid_set's binary_logloss: 0.0361\n","\u001b[36m(_ray_fit pid=8019)\u001b[0m [1000]\tvalid_set's binary_logloss: 0.0365352\u001b[32m [repeated 3x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)\u001b[0m\n","\u001b[36m(_ray_fit pid=8023)\u001b[0m [1000]\tvalid_set's binary_logloss: 0.0366522\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=8018)\u001b[0m [1000]\tvalid_set's binary_logloss: 0.0363563\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=8017)\u001b[0m [2000]\tvalid_set's binary_logloss: 0.0356903\n","\u001b[36m(_ray_fit pid=8020)\u001b[0m [2000]\tvalid_set's binary_logloss: 0.0367296\n","\u001b[36m(_ray_fit pid=8019)\u001b[0m [2000]\tvalid_set's binary_logloss: 0.0361885\n","\u001b[36m(_ray_fit pid=8022)\u001b[0m [2000]\tvalid_set's binary_logloss: 0.036917\n","\u001b[36m(_ray_fit pid=8023)\u001b[0m [2000]\tvalid_set's binary_logloss: 0.036263\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=8018)\u001b[0m [2000]\tvalid_set's binary_logloss: 0.0359798\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=8017)\u001b[0m [3000]\tvalid_set's binary_logloss: 0.0355927\n","\u001b[36m(_ray_fit pid=8020)\u001b[0m [3000]\tvalid_set's binary_logloss: 0.0366427\n","\u001b[36m(_ray_fit pid=8022)\u001b[0m [3000]\tvalid_set's binary_logloss: 0.0368437\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=8023)\u001b[0m [3000]\tvalid_set's binary_logloss: 0.0361929\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=8016)\u001b[0m [3000]\tvalid_set's binary_logloss: 0.0360491\n","\u001b[36m(_ray_fit pid=8018)\u001b[0m [3000]\tvalid_set's binary_logloss: 0.0359181\n","\u001b[36m(_ray_fit pid=8017)\u001b[0m [4000]\tvalid_set's binary_logloss: 0.0355747\n","\u001b[36m(_ray_fit pid=8020)\u001b[0m [4000]\tvalid_set's binary_logloss: 0.0366655\n","\u001b[36m(_ray_fit pid=8022)\u001b[0m [4000]\tvalid_set's binary_logloss: 0.0368454\u001b[32m [repeated 3x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=8023)\u001b[0m [4000]\tvalid_set's binary_logloss: 0.0362036\n","\u001b[36m(_ray_fit pid=8018)\u001b[0m [4000]\tvalid_set's binary_logloss: 0.0359387\n","\u001b[36m(_ray_fit pid=8017)\u001b[0m [5000]\tvalid_set's binary_logloss: 0.0356057\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(_dystack pid=7231)\u001b[0m \t-0.0361\t = Validation score   (-log_loss)\n","\u001b[36m(_dystack pid=7231)\u001b[0m \t2154.16s\t = Training   runtime\n","\u001b[36m(_dystack pid=7231)\u001b[0m \t1649.18s\t = Validation runtime\n","\u001b[36m(_dystack pid=7231)\u001b[0m Fitting model: LightGBM_BAG_L1 ... Training model for up to 4842.04s of the 8433.64s of remaining time.\n","\u001b[36m(_dystack pid=7231)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=2.14%)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[36m(_ray_fit pid=17906)\u001b[0m [1000]\tvalid_set's binary_logloss: 0.0375294\n","\u001b[36m(_ray_fit pid=17908)\u001b[0m [1000]\tvalid_set's binary_logloss: 0.0379729\u001b[32m [repeated 7x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=17909)\u001b[0m [2000]\tvalid_set's binary_logloss: 0.0367684\n","\u001b[36m(_ray_fit pid=17907)\u001b[0m [2000]\tvalid_set's binary_logloss: 0.0365629\n","\u001b[36m(_ray_fit pid=17905)\u001b[0m [2000]\tvalid_set's binary_logloss: 0.036894\u001b[32m [repeated 6x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=17906)\u001b[0m [3000]\tvalid_set's binary_logloss: 0.037296\n","\u001b[36m(_ray_fit pid=17908)\u001b[0m [3000]\tvalid_set's binary_logloss: 0.0377173\n","\u001b[36m(_ray_fit pid=17902)\u001b[0m [3000]\tvalid_set's binary_logloss: 0.0368561\u001b[32m [repeated 2x across cluster]\u001b[0m\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(_dystack pid=7231)\u001b[0m \t-0.0369\t = Validation score   (-log_loss)\n","\u001b[36m(_dystack pid=7231)\u001b[0m \t1272.15s\t = Training   runtime\n","\u001b[36m(_dystack pid=7231)\u001b[0m \t731.29s\t = Validation runtime\n","\u001b[36m(_dystack pid=7231)\u001b[0m Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 3450.4s of the 7042.0s of remaining time.\n","\u001b[36m(_dystack pid=7231)\u001b[0m \t-0.0385\t = Validation score   (-log_loss)\n","\u001b[36m(_dystack pid=7231)\u001b[0m \t606.55s\t = Training   runtime\n","\u001b[36m(_dystack pid=7231)\u001b[0m \t137.66s\t = Validation runtime\n","\u001b[36m(_dystack pid=7231)\u001b[0m Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 2703.26s of the 6294.86s of remaining time.\n","\u001b[36m(_dystack pid=7231)\u001b[0m \t-0.0388\t = Validation score   (-log_loss)\n","\u001b[36m(_dystack pid=7231)\u001b[0m \t694.2s\t = Training   runtime\n","\u001b[36m(_dystack pid=7231)\u001b[0m \t147.1s\t = Validation runtime\n","\u001b[36m(_dystack pid=7231)\u001b[0m Fitting model: CatBoost_BAG_L1 ... Training model for up to 1857.87s of the 5449.47s of remaining time.\n","\u001b[36m(_dystack pid=7231)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=2.20%)\n","\u001b[36m(_dystack pid=7231)\u001b[0m \t-0.061\t = Validation score   (-log_loss)\n","\u001b[36m(_dystack pid=7231)\u001b[0m \t1468.24s\t = Training   runtime\n","\u001b[36m(_dystack pid=7231)\u001b[0m \t2.35s\t = Validation runtime\n","\u001b[36m(_dystack pid=7231)\u001b[0m Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 383.79s of the 3975.39s of remaining time.\n","\u001b[36m(_dystack pid=7231)\u001b[0m \tWarning: Reducing model 'n_estimators' from 300 -> 130 due to low time. Expected time usage reduced from 884.8s -> 383.8s...\n","\u001b[36m(_dystack pid=7231)\u001b[0m \tNot enough time to generate out-of-fold predictions for model. Estimated time required was 415.37s compared to 348.11s of available time.\n","\u001b[36m(_dystack pid=7231)\u001b[0m \tTime limit exceeded... Skipping ExtraTreesGini_BAG_L1.\n","\u001b[36m(_dystack pid=7231)\u001b[0m Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 231.78s of the 3823.38s of remaining time.\n","\u001b[36m(_dystack pid=7231)\u001b[0m \tWarning: Reducing model 'n_estimators' from 300 -> 143 due to low time. Expected time usage reduced from 485.3s -> 231.8s...\n","\u001b[36m(_dystack pid=7231)\u001b[0m \tNot enough time to generate out-of-fold predictions for model. Estimated time required was 395.56s compared to 125.82s of available time.\n","\u001b[36m(_dystack pid=7231)\u001b[0m \tTime limit exceeded... Skipping ExtraTreesEntr_BAG_L1.\n","\u001b[36m(_dystack pid=7231)\u001b[0m Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 55.14s of the 3646.73s of remaining time.\n","\u001b[36m(_dystack pid=7231)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=3.67%)\n","\u001b[36m(_dystack pid=7231)\u001b[0m \tTime limit exceeded... Skipping NeuralNetFastAI_BAG_L1.\n","\u001b[36m(_dystack pid=7231)\u001b[0m Fitting model: XGBoost_BAG_L1 ... Training model for up to 28.35s of the 3619.95s of remaining time.\n","\u001b[36m(_dystack pid=7231)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(_dystack pid=7231)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(_dystack pid=7231)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(_dystack pid=7231)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(_dystack pid=7231)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(_dystack pid=7231)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(_dystack pid=7231)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(_dystack pid=7231)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=2.92%)\n","\u001b[36m(_dystack pid=7231)\u001b[0m \t-0.6462\t = Validation score   (-log_loss)\n","\u001b[36m(_dystack pid=7231)\u001b[0m \t563.43s\t = Training   runtime\n","\u001b[36m(_dystack pid=7231)\u001b[0m \t17.19s\t = Validation runtime\n","\u001b[36m(_dystack pid=7231)\u001b[0m Fitting model: WeightedEnsemble_L2 ... Training model for up to 717.78s of the 3049.16s of remaining time.\n","\u001b[36m(_dystack pid=7231)\u001b[0m \tEnsemble Weights: {'LightGBMXT_BAG_L1': 0.8, 'LightGBM_BAG_L1': 0.1, 'RandomForestGini_BAG_L1': 0.1}\n","\u001b[36m(_dystack pid=7231)\u001b[0m \t-0.036\t = Validation score   (-log_loss)\n","\u001b[36m(_dystack pid=7231)\u001b[0m \t6.71s\t = Training   runtime\n","\u001b[36m(_dystack pid=7231)\u001b[0m \t0.13s\t = Validation runtime\n","\u001b[36m(_dystack pid=7231)\u001b[0m Excluded models: ['KNN'] (Specified by `excluded_model_types`)\n","\u001b[36m(_dystack pid=7231)\u001b[0m Fitting 108 L2 models ...\n","\u001b[36m(_dystack pid=7231)\u001b[0m Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 3042.09s of the 3041.79s of remaining time.\n","\u001b[36m(_dystack pid=7231)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=3.11%)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[36m(_ray_fit pid=42046)\u001b[0m [1000]\tvalid_set's binary_logloss: 0.0361757\n","\u001b[36m(_ray_fit pid=42042)\u001b[0m [1000]\tvalid_set's binary_logloss: 0.0357913\n","\u001b[36m(_ray_fit pid=42043)\u001b[0m [1000]\tvalid_set's binary_logloss: 0.0365409\u001b[32m [repeated 5x across cluster]\u001b[0m\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(_dystack pid=7231)\u001b[0m \t-0.0359\t = Validation score   (-log_loss)\n","\u001b[36m(_dystack pid=7231)\u001b[0m \t824.76s\t = Training   runtime\n","\u001b[36m(_dystack pid=7231)\u001b[0m \t336.03s\t = Validation runtime\n","\u001b[36m(_dystack pid=7231)\u001b[0m Fitting model: LightGBM_BAG_L2 ... Training model for up to 2162.95s of the 2162.65s of remaining time.\n","\u001b[36m(_dystack pid=7231)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=3.11%)\n","\u001b[36m(_dystack pid=7231)\u001b[0m \t-0.0357\t = Validation score   (-log_loss)\n","\u001b[36m(_dystack pid=7231)\u001b[0m \t191.29s\t = Training   runtime\n","\u001b[36m(_dystack pid=7231)\u001b[0m \t26.66s\t = Validation runtime\n","\u001b[36m(_dystack pid=7231)\u001b[0m Fitting model: RandomForestGini_BAG_L2 ... Training model for up to 1961.77s of the 1961.48s of remaining time.\n","\u001b[36m(_dystack pid=7231)\u001b[0m \t-0.0367\t = Validation score   (-log_loss)\n","\u001b[36m(_dystack pid=7231)\u001b[0m \t993.95s\t = Training   runtime\n","\u001b[36m(_dystack pid=7231)\u001b[0m \t134.79s\t = Validation runtime\n","\u001b[36m(_dystack pid=7231)\u001b[0m Fitting model: RandomForestEntr_BAG_L2 ... Training model for up to 827.92s of the 827.62s of remaining time.\n","\u001b[36m(_dystack pid=7231)\u001b[0m \tWarning: Reducing model 'n_estimators' from 300 -> 132 due to low time. Expected time usage reduced from 1875.2s -> 827.9s...\n","\u001b[36m(_dystack pid=7231)\u001b[0m \t-0.038\t = Validation score   (-log_loss)\n","\u001b[36m(_dystack pid=7231)\u001b[0m \t530.73s\t = Training   runtime\n","\u001b[36m(_dystack pid=7231)\u001b[0m \t73.62s\t = Validation runtime\n","\u001b[36m(_dystack pid=7231)\u001b[0m Fitting model: CatBoost_BAG_L2 ... Training model for up to 221.04s of the 220.75s of remaining time.\n","\u001b[36m(_dystack pid=7231)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=3.14%)\n","\u001b[36m(_dystack pid=7231)\u001b[0m \t-0.1791\t = Validation score   (-log_loss)\n","\u001b[36m(_dystack pid=7231)\u001b[0m \t158.6s\t = Training   runtime\n","\u001b[36m(_dystack pid=7231)\u001b[0m \t1.18s\t = Validation runtime\n","\u001b[36m(_dystack pid=7231)\u001b[0m Fitting model: ExtraTreesGini_BAG_L2 ... Training model for up to 54.64s of the 54.33s of remaining time.\n","\u001b[36m(_dystack pid=7231)\u001b[0m \tWarning: Model is expected to require 1058.1s to train, which exceeds the maximum time limit of 54.6s, skipping model...\n","\u001b[36m(_dystack pid=7231)\u001b[0m \tTime limit exceeded... Skipping ExtraTreesGini_BAG_L2.\n","\u001b[36m(_dystack pid=7231)\u001b[0m Fitting model: ExtraTreesEntr_BAG_L2 ... Training model for up to 33.39s of the 33.07s of remaining time.\n","\u001b[36m(_dystack pid=7231)\u001b[0m \tWarning: Model is expected to require 1192.5s to train, which exceeds the maximum time limit of 33.4s, skipping model...\n","\u001b[36m(_dystack pid=7231)\u001b[0m \tTime limit exceeded... Skipping ExtraTreesEntr_BAG_L2.\n","\u001b[36m(_dystack pid=7231)\u001b[0m Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 10.25s of the 9.94s of remaining time.\n","\u001b[36m(_dystack pid=7231)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=5.21%)\n","\u001b[36m(_dystack pid=7231)\u001b[0m \tTime limit exceeded... Skipping NeuralNetFastAI_BAG_L2.\n","\u001b[36m(_dystack pid=7231)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(_dystack pid=7231)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(_dystack pid=7231)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(_dystack pid=7231)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(_dystack pid=7231)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(_dystack pid=7231)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(_dystack pid=7231)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(_dystack pid=7231)\u001b[0m Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the -21.65s of remaining time.\n","\u001b[36m(_dystack pid=7231)\u001b[0m \tEnsemble Weights: {'LightGBM_BAG_L2': 0.438, 'LightGBMXT_BAG_L2': 0.25, 'LightGBMXT_BAG_L1': 0.125, 'RandomForestGini_BAG_L2': 0.125, 'RandomForestEntr_BAG_L2': 0.062}\n","\u001b[36m(_dystack pid=7231)\u001b[0m \t-0.0356\t = Validation score   (-log_loss)\n","\u001b[36m(_dystack pid=7231)\u001b[0m \t12.18s\t = Training   runtime\n","\u001b[36m(_dystack pid=7231)\u001b[0m \t0.13s\t = Validation runtime\n","\u001b[36m(_dystack pid=7231)\u001b[0m AutoGluon training complete, total runtime = 10829.89s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 122.6 rows/s (346328 batch size)\n","\u001b[36m(_dystack pid=7231)\u001b[0m TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20240829_142322/ds_sub_fit/sub_fit_ho\")\n","\u001b[36m(_dystack pid=7231)\u001b[0m Deleting DyStack predictor artifacts (clean_up_fits=True) ...\n","Leaderboard on holdout data (DyStack):\n","                      model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val     fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n","0       WeightedEnsemble_L3      -0.035365  -0.035618    log_loss      676.893923    3256.013391  9311.635564                 0.014004                0.132023          12.182000            3       True         13\n","1         LightGBMXT_BAG_L2      -0.035412  -0.035857    log_loss      660.542429    3020.811968  7583.476501               115.738058              336.032358         824.756186            2       True          8\n","2           LightGBM_BAG_L2      -0.035431  -0.035749    log_loss      551.805012    2711.444383  6950.010033                 7.000641               26.664773         191.289719            2       True          9\n","3       WeightedEnsemble_L2      -0.035675  -0.036017    log_loss      521.344223    2518.259935  4039.567510                 0.010688                0.130276           6.710312            2       True          7\n","4         LightGBMXT_BAG_L1      -0.035684  -0.036124    log_loss      311.953284    1649.177269  2154.157386               311.953284             1649.177269        2154.157386            1       True          1\n","5   RandomForestGini_BAG_L2      -0.036107  -0.036727    log_loss      551.365609    2819.565384  7752.674939                 6.561237              134.785774         993.954624            2       True         10\n","6           LightGBM_BAG_L1      -0.036191  -0.036869    log_loss      200.600801     731.289924  1272.149502               200.600801              731.289924        1272.149502            1       True          2\n","7   RandomForestEntr_BAG_L2      -0.036911  -0.038032    log_loss      547.579983    2758.398463  7289.453034                 2.775611               73.618853         530.732720            2       True         11\n","8   RandomForestGini_BAG_L1      -0.038398  -0.038541    log_loss        8.779449     137.662467   606.550310                 8.779449              137.662467         606.550310            1       True          3\n","9   RandomForestEntr_BAG_L1      -0.038559  -0.038818    log_loss        7.644227     147.102261   694.196422                 7.644227              147.102261         694.196422            1       True          4\n","10          CatBoost_BAG_L1      -0.059651  -0.060984    log_loss        1.792443       2.354399  1468.235538                 1.792443                2.354399        1468.235538            1       True          5\n","11          CatBoost_BAG_L2      -0.179311  -0.179054    log_loss      545.330788    2685.962277  6917.316535                 0.526416                1.182667         158.596221            2       True         12\n","12           XGBoost_BAG_L1      -0.646226  -0.646157    log_loss       14.034167      17.193290   563.431155                14.034167               17.193290         563.431155            1       True          6\n","\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\n","\t11527s\t = DyStack   runtime |\t31673s\t = Remaining runtime\n","Starting main fit with num_stack_levels=1.\n","\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\n","Beginning AutoGluon training ... Time limit = 31673s\n","AutoGluon will save models to \"AutogluonModels/ag-20240829_142322\"\n","Train Data Rows:    3116945\n","Train Data Columns: 21\n","Label Column:       class\n","Problem Type:       binary\n","Preprocessing data ...\n","Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n","Using Feature Generators to preprocess the data ...\n","Fitting AutoMLPipelineFeatureGenerator...\n","\tAvailable Memory:                    50893.40 MB\n","\tTrain Data (Original)  Memory Usage: 2819.63 MB (5.5% of available memory)\n","\tWarning: Data size prior to feature transformation consumes 5.5% of available memory. Consider increasing memory or subsampling the data to avoid instability.\n","\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n","\tStage 1 Generators:\n","\t\tFitting AsTypeFeatureGenerator...\n","\t\t\tNote: Converting 2 features to boolean dtype as they only contain 2 unique values.\n","\tStage 2 Generators:\n","\t\tFitting FillNaFeatureGenerator...\n","\tStage 3 Generators:\n","\t\tFitting IdentityFeatureGenerator...\n","\t\tFitting CategoryFeatureGenerator...\n","\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n","\tStage 4 Generators:\n","\t\tFitting DropUniqueFeatureGenerator...\n","\tStage 5 Generators:\n","\t\tFitting DropDuplicatesFeatureGenerator...\n","\tTypes of features in original data (raw dtype, special dtypes):\n","\t\t('float', [])  :  3 | ['cap_diameter', 'stem_height', 'stem_width']\n","\t\t('int', [])    :  3 | ['id', 'does_bruise_or_bleed', 'has_ring']\n","\t\t('object', []) : 15 | ['cap_shape', 'cap_surface', 'cap_color', 'gill_attachment', 'gill_spacing', ...]\n","\tTypes of features in processed data (raw dtype, special dtypes):\n","\t\t('category', [])  : 15 | ['cap_shape', 'cap_surface', 'cap_color', 'gill_attachment', 'gill_spacing', ...]\n","\t\t('float', [])     :  3 | ['cap_diameter', 'stem_height', 'stem_width']\n","\t\t('int', [])       :  1 | ['id']\n","\t\t('int', ['bool']) :  2 | ['does_bruise_or_bleed', 'has_ring']\n","\t28.8s = Fit runtime\n","\t21 features in original data used to generate 21 features in processed data.\n","\tTrain Data (Processed) Memory Usage: 145.66 MB (0.3% of available memory)\n","Data preprocessing and feature engineering runtime = 31.95s ...\n","AutoGluon will gauge predictive performance using evaluation metric: 'log_loss'\n","\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n","\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n","\tTo change this, specify the eval_metric parameter of Predictor()\n","Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n","User-specified model hyperparameters to be fit:\n","{\n","\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n","\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n","\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n","\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n","\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n","\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n","\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n","\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n","}\n","AutoGluon will fit 2 stack levels (L1 to L2) ...\n","Excluded models: ['KNN'] (Specified by `excluded_model_types`)\n","Fitting 108 L1 models ...\n","Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 21088.95s of the 31641.32s of remaining time.\n","\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.99%)\n","\t-0.0361\t = Validation score   (-log_loss)\n","\t2454.8s\t = Training   runtime\n","\t1861.79s\t = Validation runtime\n","Fitting model: LightGBM_BAG_L1 ... Training model for up to 18378.78s of the 28931.15s of remaining time.\n","\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.98%)\n","\t-0.0367\t = Validation score   (-log_loss)\n","\t1437.02s\t = Training   runtime\n","\t834.48s\t = Validation runtime\n","Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 16827.09s of the 27379.46s of remaining time.\n","\t-0.0384\t = Validation score   (-log_loss)\n","\t803.53s\t = Training   runtime\n","\t148.28s\t = Validation runtime\n","Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 15872.75s of the 26425.12s of remaining time.\n","\t-0.0386\t = Validation score   (-log_loss)\n","\t844.9s\t = Training   runtime\n","\t154.42s\t = Validation runtime\n","Fitting model: CatBoost_BAG_L1 ... Training model for up to 14870.82s of the 25423.19s of remaining time.\n","\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=2.05%)\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-c9fb0ac93432>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Fit the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m predictor.fit(train_data=train_data,\n\u001b[0m\u001b[1;32m     13\u001b[0m               \u001b[0mtime_limit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3600\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m               \u001b[0mpresets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"best_quality\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autogluon/core/utils/decorators.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mgargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mother_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mgargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mgkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autogluon/tabular/predictor/predictor.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, train_data, tuning_data, time_limit, presets, hyperparameters, feature_metadata, infer_limit, infer_limit_batch_size, fit_weighted_ensemble, fit_full_last_level_weighted_ensemble, full_weighted_ensemble_additionally, dynamic_stacking, calibrate_decision_threshold, num_cpus, num_gpus, **kwargs)\u001b[0m\n\u001b[1;32m   1165\u001b[0m             \u001b[0mag_fit_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"time_limit\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime_limit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1167\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag_fit_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag_fit_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag_post_fit_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag_post_fit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1169\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autogluon/tabular/predictor/predictor.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, ag_fit_kwargs, ag_post_fit_kwargs)\u001b[0m\n\u001b[1;32m   1171\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag_fit_kwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag_post_fit_kwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msilent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Save predictor to disk to enable prediction and training after interrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1173\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_learner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mag_fit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1174\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_post_fit_vars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_post_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mag_post_fit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autogluon/tabular/learner/abstract_learner.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, X_val, **kwargs)\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Learner is already fit.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_fit_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     def _fit(\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autogluon/tabular/learner/default_learner.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, X_val, X_unlabeled, holdout_frac, num_bag_folds, num_bag_sets, time_limit, infer_limit, infer_limit_batch_size, verbosity, **trainer_fit_kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m         trainer.fit(\n\u001b[0m\u001b[1;32m    123\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autogluon/tabular/trainer/auto_trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, hyperparameters, X_val, y_val, X_unlabeled, holdout_frac, num_stack_levels, core_kwargs, aux_kwargs, time_limit, infer_limit, infer_limit_batch_size, use_bag_holdout, groups, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         self._train_multi_and_ensemble(\n\u001b[0m\u001b[1;32m    126\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\u001b[0m in \u001b[0;36m_train_multi_and_ensemble\u001b[0;34m(self, X, y, X_val, y_val, hyperparameters, X_unlabeled, num_stack_levels, time_limit, groups, **kwargs)\u001b[0m\n\u001b[1;32m   2587\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_rows_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2588\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_cols_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2589\u001b[0;31m         model_names_fit = self.train_multi_levels(\n\u001b[0m\u001b[1;32m   2590\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2591\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\u001b[0m in \u001b[0;36mtrain_multi_levels\u001b[0;34m(self, X, y, hyperparameters, X_val, y_val, X_unlabeled, base_model_names, core_kwargs, aux_kwargs, level_start, level_end, time_limit, name_suffix, relative_stack, level_time_modifier, infer_limit, infer_limit_batch_size)\u001b[0m\n\u001b[1;32m    450\u001b[0m                 \u001b[0mcore_kwargs_level\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"time_limit\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcore_kwargs_level\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"time_limit\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_limit_core\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m                 \u001b[0maux_kwargs_level\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"time_limit\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maux_kwargs_level\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"time_limit\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_limit_aux\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m             base_model_names, aux_models = self.stack_new_level(\n\u001b[0m\u001b[1;32m    453\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m                 \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\u001b[0m in \u001b[0;36mstack_new_level\u001b[0;34m(self, X, y, models, X_val, y_val, X_unlabeled, level, base_model_names, core_kwargs, aux_kwargs, name_suffix, infer_limit, infer_limit_batch_size, full_weighted_ensemble, additional_full_weighted_ensemble)\u001b[0m\n\u001b[1;32m    598\u001b[0m             \u001b[0mcore_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"name_suffix\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcore_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"name_suffix\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname_suffix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m             \u001b[0maux_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"name_suffix\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maux_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"name_suffix\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname_suffix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m         core_models = self.stack_new_level_core(\n\u001b[0m\u001b[1;32m    601\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\u001b[0m in \u001b[0;36mstack_new_level_core\u001b[0;34m(self, X, y, models, X_val, y_val, X_unlabeled, level, base_model_names, stack_name, ag_args, ag_args_fit, ag_args_ensemble, included_model_types, excluded_model_types, ensemble_type, name_suffix, get_models_func, refit_full, infer_limit, infer_limit_batch_size, **kwargs)\u001b[0m\n\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m         \u001b[0;31m# FIXME: TODO: v0.1 X_unlabeled isn't cached so it won't be available during refit_full or fit_extra.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m         return self._train_multi(\n\u001b[0m\u001b[1;32m    731\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_init\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\u001b[0m in \u001b[0;36m_train_multi\u001b[0;34m(self, X, y, models, hyperparameter_tune_kwargs, feature_prune_kwargs, k_fold, n_repeats, n_repeat_start, time_limit, **kwargs)\u001b[0m\n\u001b[1;32m   2537\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_repeat_start\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2538\u001b[0m             \u001b[0mtime_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2539\u001b[0;31m             model_names_trained = self._train_multi_initial(\n\u001b[0m\u001b[1;32m   2540\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2541\u001b[0m                 \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\u001b[0m in \u001b[0;36m_train_multi_initial\u001b[0;34m(self, X, y, models, k_fold, n_repeats, hyperparameter_tune_kwargs, time_limit, feature_prune_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m   2386\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2387\u001b[0m             \u001b[0mtime_ratio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhpo_time_ratio\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhpo_enabled\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2388\u001b[0;31m             models = self._train_multi_fold(\n\u001b[0m\u001b[1;32m   2389\u001b[0m                 \u001b[0mmodels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2390\u001b[0m                 \u001b[0mhyperparameter_tune_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhyperparameter_tune_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\u001b[0m in \u001b[0;36m_train_multi_fold\u001b[0;34m(self, X, y, models, time_limit, time_split, time_ratio, hyperparameter_tune_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m   2494\u001b[0m                     \u001b[0mtime_start_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2495\u001b[0m                     \u001b[0mtime_left\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime_limit\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime_start_model\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime_start\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2496\u001b[0;31m             model_name_trained_lst = self._train_single_full(\n\u001b[0m\u001b[1;32m   2497\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_limit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime_left\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyperparameter_tune_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhyperparameter_tune_kwargs_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2498\u001b[0m             )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\u001b[0m in \u001b[0;36m_train_single_full\u001b[0;34m(self, X, y, model, X_unlabeled, X_val, y_val, X_pseudo, y_pseudo, feature_prune, hyperparameter_tune_kwargs, stack_name, k_fold, k_fold_start, k_fold_end, n_repeats, n_repeat_start, level, time_limit, fit_kwargs, compute_score, total_resources, **kwargs)\u001b[0m\n\u001b[1;32m   2267\u001b[0m                 )\n\u001b[1;32m   2268\u001b[0m                 \u001b[0mmodel_fit_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbagged_model_fit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2269\u001b[0;31m             model_names_trained = self._train_and_save(\n\u001b[0m\u001b[1;32m   2270\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2271\u001b[0m                 \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\u001b[0m in \u001b[0;36m_train_and_save\u001b[0;34m(self, X, y, model, X_val, y_val, stack_name, level, compute_score, total_resources, **model_fit_kwargs)\u001b[0m\n\u001b[1;32m   1902\u001b[0m                     \u001b[0mmodel_fit_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"X_pseudo\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1903\u001b[0m                     \u001b[0mmodel_fit_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"y_pseudo\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1904\u001b[0;31m                 \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_resources\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_resources\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmodel_fit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1905\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1906\u001b[0m             \u001b[0mfit_end_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\u001b[0m in \u001b[0;36m_train_single\u001b[0;34m(self, X, y, model, X_val, y_val, total_resources, **model_fit_kwargs)\u001b[0m\n\u001b[1;32m   1842\u001b[0m         \u001b[0mReturns\u001b[0m \u001b[0mtrained\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1843\u001b[0m         \"\"\"\n\u001b[0;32m-> 1844\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_resources\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_resources\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmodel_fit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1845\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1846\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_fit_resources\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_fit_memory_usage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    857\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, compute_base_preds, time_limit, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtime_limit\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m             \u001b[0mtime_limit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime_limit\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_limit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime_limit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_stack_columns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_column_prefix_lst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, X_val, y_val, X_pseudo, y_pseudo, k_fold, k_fold_start, k_fold_end, n_repeats, n_repeat_start, groups, _skip_oof, **kwargs)\u001b[0m\n\u001b[1;32m    286\u001b[0m                     \u001b[0;31m# Reserve time for final refit model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"time_limit\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"time_limit\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mfolds_to_fit\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfolds_to_fit\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             self._fit_folds(\n\u001b[0m\u001b[1;32m    289\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m                 \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\u001b[0m in \u001b[0;36m_fit_folds\u001b[0;34m(self, X, y, model_base, X_pseudo, y_pseudo, k_fold, k_fold_start, k_fold_end, n_repeats, n_repeat_start, time_limit, sample_weight, save_folds, groups, num_cpus, num_gpus, **kwargs)\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfold_fit_args\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfold_fit_args_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m             \u001b[0mfold_fitting_strategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschedule_fold_model_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mfold_fit_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 714\u001b[0;31m         \u001b[0mfold_fitting_strategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafter_all_folds_scheduled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    715\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\u001b[0m in \u001b[0;36mafter_all_folds_scheduled\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    666\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_pseudo_sequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_pseudo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pseudo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_base_ref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_limit_fold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_node_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 668\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_parallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_pseudo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pseudo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_base_ref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_limit_fold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_node_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    669\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mterminate_all_unfinished_tasks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munfinished_tasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\u001b[0m in \u001b[0;36m_run_parallel\u001b[0;34m(self, X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\u001b[0m\n\u001b[1;32m    605\u001b[0m         \u001b[0munfinished\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjob_refs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0munfinished\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 607\u001b[0;31m             \u001b[0mfinished\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munfinished\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munfinished\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_returns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    608\u001b[0m             \u001b[0mfinished\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinished\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m             \u001b[0mfold_ctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjob_fold_map\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinished\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ray/_private/auto_init_hook.py\u001b[0m in \u001b[0;36mauto_init_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mauto_init_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mauto_init_ray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mauto_init_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"init\"\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mis_client_mode_enabled_by_default\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(ray_waitables, num_returns, timeout, fetch_local)\u001b[0m\n\u001b[1;32m   2896\u001b[0m         \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2897\u001b[0m         \u001b[0mtimeout_milliseconds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2898\u001b[0;31m         ready_ids, remaining_ids = worker.core_worker.wait(\n\u001b[0m\u001b[1;32m   2899\u001b[0m             \u001b[0mray_waitables\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2900\u001b[0m             \u001b[0mnum_returns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mpython/ray/_raylet.pyx\u001b[0m in \u001b[0;36mray._raylet.CoreWorker.wait\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpython/ray/_raylet.pyx\u001b[0m in \u001b[0;36mray._raylet.check_status\u001b[0;34m()\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["leaderboard_test = predictor.leaderboard()\n","leaderboard_test"],"metadata":{"trusted":true,"id":"MLWAg5Z9dCUF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#test['preds'] = predictor.predict(test_data)"],"metadata":{"id":"VbrOi1fgdCUF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["p = cloudpickle.dumps(predictor)\n","with open(os.path.join(base_path, 'Autogluon_12h_best_gpu.pkl'), \"wb\") as f:\n","    f.write(p)"],"metadata":{"execution":{"iopub.status.busy":"2024-08-29T04:43:22.913709Z","iopub.execute_input":"2024-08-29T04:43:22.914837Z","iopub.status.idle":"2024-08-29T04:43:23.215966Z","shell.execute_reply.started":"2024-08-29T04:43:22.914796Z","shell.execute_reply":"2024-08-29T04:43:23.214518Z"},"trusted":true,"id":"SJgpom1XdCUF","executionInfo":{"status":"aborted","timestamp":1724968540534,"user_tz":240,"elapsed":8,"user":{"displayName":"Fabián Alberto Reyes Madrid","userId":"11772448517145602220"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"KuprBZqPdCUG"},"execution_count":null,"outputs":[]}]}